# URL-Spider

写一个获取网站存在的 URL 的爬虫，用于方便渗透测试和后期写扫描器。

### 进度：

    [+] URL-Spider.py已编写完成（2019-09-20）
    [+] 优化了URL-Spider.py的运行速度，比上个版本快了10倍以上（2019-09-19）
    [+] 现在可以通过输入URL和爬取深度来对网站公开的URL进行爬取
    [+] dic.py  枚举字典生成
        （会根据网站生成一些针对性字典）(写成半模块的了，独立好像也可以独立运行，可以测试一下)
    
### 未实现功能：

    [-] 调用各个脚本的 start.py
    [-] 从文件导入URL（测试版已完成，还未上传）
    [-] 通过枚举的方式找出一些隐藏URL
    

### 使用方法：

##### URL-Spider.py（已完成）

    开始使用  
        python3 URL-Spider.py
        根据提示进行输入URL和爬取深度
        结束后会在目录下生成Output文件夹
        
    脚本中引用的模块：
        requests
        os
     
    说明：
        通过返回包中查找可能是URL的字符串进行访问尝试，
        将测试完的URL以状态码作为区分，分为 20X / 403 / 40X / other 四个文件存储
        扫描深度的URL来源和20X文件夹的内容相同，但不是从20X文件中获取的。
        
##### dic.py（半成品）
    
    开始使用
        python3 dic.py
        根据提示输入网站名称和语言
        结束后会在目录下生成一个dic_files.txt字典文件
        
    脚本中引用的模块：
        无
        
    说明：
        提取dir文件中的字典
        针对性生成网站可能存在的备份文件名
        
